apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "2"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"ai-code-app-ollama","namespace":"default"},"spec":{"template":{"spec":{"containers":[{"image":"ollama/ollama:latest","imagePullPolicy":"Always","name":"ai-code-app-ollama","resources":{"limits":{"cpu":"10","memory":"10Gi"},"requests":{"cpu":"10","memory":"10Gi"}}}]}}}}
    meta.helm.sh/release-name: ai-code-app
    meta.helm.sh/release-namespace: default
  creationTimestamp: "2025-04-26T20:08:36Z"
  generation: 2
  labels:
    app.kubernetes.io/component: ollama
    app.kubernetes.io/instance: ai-code-app
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ai-code-app
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: ai-code-app-0.1.0
  name: ai-code-app-ollama
  namespace: default
  resourceVersion: "1747"
  uid: 5f47c611-68c0-43a2-9ed7-a71b17ec57b7
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: ollama
      app.kubernetes.io/instance: ai-code-app
      app.kubernetes.io/name: ai-code-app
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app.kubernetes.io/component: ollama
        app.kubernetes.io/instance: ai-code-app
        app.kubernetes.io/name: ai-code-app
    spec:
      containers:
      - image: ollama/ollama:latest
        imagePullPolicy: Always
        name: ai-code-app-ollama
        resources:
          limits:
            cpu: "10"
            memory: 10Gi
          requests:
            cpu: "10"
            memory: 10Gi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      - args:
        - serve
        command:
        - ollama
        env:
        - name: OLLAMA_ORIGINS
          value: http://ai-code-app,http://ai-code-app:5000,http://localhost,http://localhost:*,http://0.0.0.0:*
        image: ollama/ollama:latest
        imagePullPolicy: Always
        lifecycle:
          postStart:
            exec:
              command:
              - /bin/sh
              - -c
              - ollama pull tinyllama
        name: ollama
        ports:
        - containerPort: 11434
          name: http
          protocol: TCP
        resources:
          limits:
            cpu: "4"
            memory: 5Gi
          requests:
            cpu: "2"
            memory: 2Gi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 1
  conditions:
  - lastTransitionTime: "2025-04-26T20:15:33Z"
    lastUpdateTime: "2025-04-26T20:15:33Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2025-04-26T20:08:36Z"
    lastUpdateTime: "2025-04-26T20:31:32Z"
    message: ReplicaSet "ai-code-app-ollama-66bc8684b9" is progressing.
    reason: ReplicaSetUpdated
    status: "True"
    type: Progressing
  observedGeneration: 2
  readyReplicas: 1
  replicas: 2
  unavailableReplicas: 1
  updatedReplicas: 1
