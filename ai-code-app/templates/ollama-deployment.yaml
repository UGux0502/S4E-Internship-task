apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ai-code-app.fullname" . }}-ollama
  labels:
    {{- include "ai-code-app.labels" . | nindent 4 }}
    app.kubernetes.io/component: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      {{- include "ai-code-app.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: ollama
  template:
    metadata:
      labels:
        {{- include "ai-code-app.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: ollama
    spec:
      containers:
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          command: ["ollama"]
          args: ["serve"]
          lifecycle:
            postStart:
              exec:
                command: ["/bin/sh", "-c", "ollama pull tinyllama"]
          env:
            - name: OLLAMA_ORIGINS
              value: "http://ai-code-app,http://ai-code-app:5000,http://localhost,http://localhost:*,http://0.0.0.0:*"
          resources:
            requests:
              cpu: "4"
              memory: "6Gi"
            limits:
              cpu: "8"
              memory: "10Gi"